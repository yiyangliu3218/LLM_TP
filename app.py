#!/usr/bin/env python3
"""
åŸºäºLLMçš„è‡ªåŠ¨è¯é¢˜å»ºæ¨¡+è¯„ä¼°+é—­ç¯ä¼˜åŒ–ç³»ç»Ÿ
Gradio Webç•Œé¢
"""

import gradio as gr
import os
import sys
import json
import tempfile
import pandas as pd
from datetime import datetime
from typing import Dict, Any, Tuple

# æ·»åŠ è‡ªå®šä¹‰æ¨¡å—è·¯å¾„
sys.path.append('./custom_pipeline')

def setup_environment():
    """è®¾ç½®ç¯å¢ƒ"""
    directories = ['data/input', 'data/output', 'results', 'prompts', 'logs']
    for directory in directories:
        os.makedirs(directory, exist_ok=True)

def analyze_excel_file(excel_file) -> Dict[str, Any]:
    """åˆ†æä¸Šä¼ çš„Excelæ–‡ä»¶"""
    if excel_file is None:
        return {"error": "è¯·ä¸Šä¼ Excelæ–‡ä»¶"}
    
    try:
        # ä¿å­˜ä¸´æ—¶æ–‡ä»¶
        temp_path = tempfile.mktemp(suffix='.xlsx')
        with open(temp_path, 'wb') as f:
            f.write(excel_file)
        
        # è¯»å–Excelæ–‡ä»¶
        df = pd.read_excel(temp_path)
        
        # åˆ†ææ•°æ®
        analysis = {
            "total_rows": len(df),
            "total_columns": len(df.columns),
            "columns": list(df.columns),
            "data_types": df.dtypes.to_dict(),
            "missing_values": df.isnull().sum().to_dict(),
            "sample_data": df.head(3).to_dict('records')
        }
        
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        os.unlink(temp_path)
        
        return analysis
        
    except Exception as e:
        return {"error": f"æ–‡ä»¶åˆ†æå¤±è´¥: {str(e)}"}

def process_excel_file(excel_file, num_topics, max_iterations, sample_size, 
                      api_type, model_name, temperature, optimization_threshold) -> Dict[str, Any]:
    """å¤„ç†ä¸Šä¼ çš„Excelæ–‡ä»¶"""
    
    if excel_file is None:
        return {"error": "è¯·ä¸Šä¼ Excelæ–‡ä»¶"}
    
    try:
        # ä¿å­˜ä¸´æ—¶æ–‡ä»¶
        temp_path = tempfile.mktemp(suffix='.xlsx')
        with open(temp_path, 'wb') as f:
            f.write(excel_file)
        
        # åˆ›å»ºé…ç½®
        config = {
            'api_type': api_type,
            'model_name': model_name,
            'num_topics': num_topics,
            'max_iterations': max_iterations,
            'sample_size': sample_size,
            'temperature': temperature,
            'optimization_threshold': optimization_threshold,
            'evaluation_aspects': [
                'coherence', 'consistency', 'fluency', 'relevance', 'diversity'
            ]
        }
        
        # è¿è¡Œé—­ç¯ç³»ç»Ÿ
        from custom_pipeline.feedback_loop import ClosedLoopTopicModeling
        
        pipeline = ClosedLoopTopicModeling(temp_path, config)
        results = pipeline.run_complete_pipeline(
            max_iterations=max_iterations,
            sample_size=sample_size
        )
        
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        os.unlink(temp_path)
        
        # æ ¼å¼åŒ–ç»“æœ
        formatted_results = {
            "æœ€ä½³åˆ†æ•°": f"{results.get('evaluation', {}).get('overall_score', 0):.2f}/5.00",
            "ä¼˜åŒ–è½®æ•°": results.get('iteration', 0),
            "è¯é¢˜æ•°é‡": len(results.get('topics', {})),
            "å¤„ç†æ–‡æ¡£æ•°": results.get('topics', {}).get('metadata', {}).get('total_documents', 0),
            "å„ç»´åº¦è¯„åˆ†": {}
        }
        
        # æ·»åŠ å„ç»´åº¦è¯„åˆ†
        evaluation = results.get('evaluation', {})
        for aspect, result in evaluation.items():
            if aspect not in ['overall_score', 'metadata']:
                formatted_results["å„ç»´åº¦è¯„åˆ†"][aspect] = f"{result.get('score', 0):.2f}/5.00"
        
        return formatted_results
        
    except Exception as e:
        return {"error": f"å¤„ç†å¤±è´¥: {str(e)}"}

def run_data_preprocessing_only(excel_file, sample_size) -> Dict[str, Any]:
    """ä»…è¿è¡Œæ•°æ®é¢„å¤„ç†"""
    if excel_file is None:
        return {"error": "è¯·ä¸Šä¼ Excelæ–‡ä»¶"}
    
    try:
        # ä¿å­˜ä¸´æ—¶æ–‡ä»¶
        temp_path = tempfile.mktemp(suffix='.xlsx')
        with open(temp_path, 'wb') as f:
            f.write(excel_file)
        
        from custom_pipeline.data_processor import DatasetProcessor
        
        processor = DatasetProcessor(temp_path)
        documents = processor.prepare_for_topicgpt(
            text_column="Translated Post Description",
            max_docs=1000,
            sample_size=sample_size
        )
        processor.save_to_jsonl(documents, "data/input/dataset.jsonl")
        stats = processor.get_data_statistics()
        
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        os.unlink(temp_path)
        
        return {
            "å¤„ç†æ–‡æ¡£æ•°": stats['total_documents'],
            "å¹³å‡æ–‡æœ¬é•¿åº¦": f"{stats['avg_text_length']:.1f}",
            "æœ€çŸ­æ–‡æœ¬é•¿åº¦": stats['min_text_length'],
            "æœ€é•¿æ–‡æœ¬é•¿åº¦": stats['max_text_length'],
            "è¯­è¨€ç§ç±»": len(stats['languages']),
            "æƒ…æ„Ÿç±»åˆ«": len(stats['sentiments'])
        }
        
    except Exception as e:
        return {"error": f"æ•°æ®é¢„å¤„ç†å¤±è´¥: {str(e)}"}

def run_topic_modeling_only(excel_file, num_topics, sample_size, api_type, model_name, temperature) -> Dict[str, Any]:
    """ä»…è¿è¡Œè¯é¢˜å»ºæ¨¡"""
    if excel_file is None:
        return {"error": "è¯·ä¸Šä¼ Excelæ–‡ä»¶"}
    
    try:
        # ä¿å­˜ä¸´æ—¶æ–‡ä»¶
        temp_path = tempfile.mktemp(suffix='.xlsx')
        with open(temp_path, 'wb') as f:
            f.write(excel_file)
        
        # æ•°æ®é¢„å¤„ç†
        from custom_pipeline.data_processor import DatasetProcessor
        processor = DatasetProcessor(temp_path)
        documents = processor.prepare_for_topicgpt(
            text_column="Translated Post Description",
            max_docs=1000,
            sample_size=sample_size
        )
        processor.save_to_jsonl(documents, "data/input/dataset.jsonl")
        
        # è¯é¢˜å»ºæ¨¡
        config = {
            'api_type': api_type,
            'model_name': model_name,
            'num_topics': num_topics,
            'temperature': temperature
        }
        
        from custom_pipeline.topicgpt_runner import CustomTopicGPTRunner
        runner = CustomTopicGPTRunner(config)
        results = runner.run_topic_modeling(documents)
        
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        os.unlink(temp_path)
        
        return {
            "ç”Ÿæˆè¯é¢˜æ•°": len(results.get('topics', {})),
            "å¤„ç†æ–‡æ¡£æ•°": len(documents),
            "è¯é¢˜åˆ—è¡¨": list(results.get('topics', {}).keys())
        }
        
    except Exception as e:
        return {"error": f"è¯é¢˜å»ºæ¨¡å¤±è´¥: {str(e)}"}

def run_evaluation_only() -> Dict[str, Any]:
    """ä»…è¿è¡Œè¯„ä¼°"""
    try:
        if not os.path.exists('data/output/topicgpt_results/topicgpt_results.json'):
            return {"error": "æœªæ‰¾åˆ°è¯é¢˜å»ºæ¨¡ç»“æœï¼Œè¯·å…ˆè¿è¡Œè¯é¢˜å»ºæ¨¡"}
        
        from custom_pipeline.geval_runner import CustomGEvalRunner
        geval_runner = CustomGEvalRunner()
        
        geval_input = geval_runner.prepare_geval_input(
            'data/output/topicgpt_results/topicgpt_results.json',
            'data/input/dataset.jsonl'
        )
        eval_results = geval_runner.run_evaluation(geval_input)
        
        return {
            "æ€»ä½“è¯„åˆ†": f"{eval_results['overall_score']:.2f}/5.00",
            "å„ç»´åº¦è¯„åˆ†": {
                aspect: f"{result.get('score', 0):.2f}/5.00"
                for aspect, result in eval_results.items()
                if aspect not in ['overall_score', 'metadata']
            }
        }
        
    except Exception as e:
        return {"error": f"è¯„ä¼°å¤±è´¥: {str(e)}"}

def get_results_summary() -> str:
    """è·å–ç»“æœæ‘˜è¦"""
    try:
        summary = []
        
        # æ£€æŸ¥è¯é¢˜å»ºæ¨¡ç»“æœ
        if os.path.exists('data/output/topicgpt_results/topicgpt_results.json'):
            with open('data/output/topicgpt_results/topicgpt_results.json', 'r', encoding='utf-8') as f:
                topic_results = json.load(f)
            summary.append(f"âœ… è¯é¢˜å»ºæ¨¡å®Œæˆï¼Œç”Ÿæˆäº† {len(topic_results.get('topics', {}))} ä¸ªè¯é¢˜")
        
        # æ£€æŸ¥è¯„ä¼°ç»“æœ
        if os.path.exists('results/geval_results.json'):
            with open('results/geval_results.json', 'r', encoding='utf-8') as f:
                eval_results = json.load(f)
            summary.append(f"âœ… è´¨é‡è¯„ä¼°å®Œæˆï¼Œæ€»åˆ†: {eval_results.get('overall_score', 0):.2f}/5.00")
        
        # æ£€æŸ¥ä¼˜åŒ–æŠ¥å‘Š
        if os.path.exists('results/optimization_report.md'):
            summary.append("âœ… ä¼˜åŒ–æŠ¥å‘Šå·²ç”Ÿæˆ")
        
        if not summary:
            summary.append("æš‚æ— ç»“æœ")
        
        return "\n".join(summary)
        
    except Exception as e:
        return f"è·å–ç»“æœæ‘˜è¦å¤±è´¥: {str(e)}"

# åˆ›å»ºGradioç•Œé¢
def create_interface():
    """åˆ›å»ºGradioç•Œé¢"""
    
    with gr.Blocks(title="åŸºäºLLMçš„è‡ªåŠ¨è¯é¢˜å»ºæ¨¡+è¯„ä¼°+é—­ç¯ä¼˜åŒ–ç³»ç»Ÿ", theme=gr.themes.Soft()) as demo:
        
        gr.Markdown("""
        # ğŸ¯ åŸºäºLLMçš„è‡ªåŠ¨è¯é¢˜å»ºæ¨¡+è¯„ä¼°+é—­ç¯ä¼˜åŒ–ç³»ç»Ÿ
        
        æœ¬ç³»ç»Ÿé›†æˆäº†TopicGPTå’ŒG-Evalï¼Œæä¾›å®Œæ•´çš„è¯é¢˜å»ºæ¨¡ã€è´¨é‡è¯„ä¼°å’Œè‡ªåŠ¨ä¼˜åŒ–åŠŸèƒ½ã€‚
        
        ## åŠŸèƒ½ç‰¹ç‚¹
        - ğŸ“Š **æ™ºèƒ½è¯é¢˜å»ºæ¨¡**: åŸºäºLLMçš„è‡ªåŠ¨è¯é¢˜å‘ç°å’Œåˆ†é…
        - ğŸ“ˆ **è´¨é‡è¯„ä¼°**: å¤šç»´åº¦è‡ªåŠ¨è¯„ä¼°è¯é¢˜å»ºæ¨¡è´¨é‡
        - ğŸ”„ **é—­ç¯ä¼˜åŒ–**: åŸºäºè¯„ä¼°ç»“æœçš„è‡ªåŠ¨å‚æ•°ä¼˜åŒ–
        - ğŸ¨ **ç”¨æˆ·å‹å¥½**: ç®€æ´çš„Webç•Œé¢æ“ä½œ
        
        ## ä½¿ç”¨è¯´æ˜
        1. ä¸Šä¼ Excelæ•°æ®é›†æ–‡ä»¶
        2. é…ç½®å‚æ•°ï¼ˆå¯é€‰ï¼‰
        3. é€‰æ‹©è¿è¡Œæ¨¡å¼
        4. æŸ¥çœ‹ç»“æœå’ŒæŠ¥å‘Š
        """)
        
        with gr.Tab("ğŸ“‹ æ•°æ®åˆ†æ"):
            gr.Markdown("### æ•°æ®é›†åˆ†æ")
            with gr.Row():
                excel_file_analysis = gr.File(label="ä¸Šä¼ Excelæ–‡ä»¶", file_types=['.xlsx', '.xls'])
                analyze_btn = gr.Button("ğŸ” åˆ†ææ•°æ®", variant="primary")
            
            analysis_output = gr.JSON(label="æ•°æ®åˆ†æç»“æœ")
            analyze_btn.click(analyze_excel_file, inputs=[excel_file_analysis], outputs=[analysis_output])
        
        with gr.Tab("ğŸš€ å®Œæ•´æµç¨‹"):
            gr.Markdown("### é—­ç¯è¯é¢˜å»ºæ¨¡ç³»ç»Ÿ")
            
            with gr.Row():
                with gr.Column():
                    excel_file = gr.File(label="ä¸Šä¼ Excelæ•°æ®é›†", file_types=['.xlsx', '.xls'])
                    
                    gr.Markdown("#### åŸºæœ¬å‚æ•°")
                    with gr.Row():
                        num_topics = gr.Slider(3, 15, value=8, step=1, label="è¯é¢˜æ•°é‡")
                        max_iterations = gr.Slider(1, 5, value=3, step=1, label="æœ€å¤§ä¼˜åŒ–è½®æ•°")
                    
                    sample_size = gr.Slider(100, 1000, value=500, step=50, label="é‡‡æ ·å¤§å°")
                    
                    gr.Markdown("#### æ¨¡å‹å‚æ•°")
                    with gr.Row():
                        api_type = gr.Dropdown(
                            choices=['openai', 'huggingface', 'local'],
                            value='openai',
                            label="APIç±»å‹"
                        )
                        model_name = gr.Textbox(
                            value='gpt-3.5-turbo',
                            label="æ¨¡å‹åç§°"
                        )
                    
                    with gr.Row():
                        temperature = gr.Slider(0.1, 1.0, value=0.7, step=0.1, label="æ¸©åº¦å‚æ•°")
                        optimization_threshold = gr.Slider(1.0, 5.0, value=3.0, step=0.1, label="ä¼˜åŒ–é˜ˆå€¼")
                
                with gr.Column():
                    run_btn = gr.Button("ğŸ¯ è¿è¡Œå®Œæ•´æµç¨‹", variant="primary", size="lg")
                    results_output = gr.JSON(label="è¿è¡Œç»“æœ")
        
            run_btn.click(
                process_excel_file,
                inputs=[excel_file, num_topics, max_iterations, sample_size, 
                       api_type, model_name, temperature, optimization_threshold],
                outputs=[results_output]
            )
        
        with gr.Tab("ğŸ”§ åˆ†æ­¥æ‰§è¡Œ"):
            gr.Markdown("### åˆ†æ­¥éª¤æ‰§è¡Œ")
            
            with gr.Accordion("ğŸ“‹ æ•°æ®é¢„å¤„ç†", open=False):
                with gr.Row():
                    excel_file_preprocess = gr.File(label="ä¸Šä¼ Excelæ–‡ä»¶", file_types=['.xlsx', '.xls'])
                    sample_size_preprocess = gr.Slider(100, 1000, value=500, step=50, label="é‡‡æ ·å¤§å°")
                    preprocess_btn = gr.Button("ğŸ“‹ æ•°æ®é¢„å¤„ç†", variant="secondary")
                
                preprocess_output = gr.JSON(label="é¢„å¤„ç†ç»“æœ")
                preprocess_btn.click(
                    run_data_preprocessing_only,
                    inputs=[excel_file_preprocess, sample_size_preprocess],
                    outputs=[preprocess_output]
                )
            
            with gr.Accordion("ğŸš€ è¯é¢˜å»ºæ¨¡", open=False):
                with gr.Row():
                    excel_file_topic = gr.File(label="ä¸Šä¼ Excelæ–‡ä»¶", file_types=['.xlsx', '.xls'])
                    num_topics_topic = gr.Slider(3, 15, value=8, step=1, label="è¯é¢˜æ•°é‡")
                    sample_size_topic = gr.Slider(100, 1000, value=500, step=50, label="é‡‡æ ·å¤§å°")
                
                with gr.Row():
                    api_type_topic = gr.Dropdown(choices=['openai', 'huggingface', 'local'], value='openai', label="APIç±»å‹")
                    model_name_topic = gr.Textbox(value='gpt-3.5-turbo', label="æ¨¡å‹åç§°")
                    temperature_topic = gr.Slider(0.1, 1.0, value=0.7, step=0.1, label="æ¸©åº¦å‚æ•°")
                
                topic_btn = gr.Button("ğŸš€ è¯é¢˜å»ºæ¨¡", variant="secondary")
                topic_output = gr.JSON(label="è¯é¢˜å»ºæ¨¡ç»“æœ")
                
                topic_btn.click(
                    run_topic_modeling_only,
                    inputs=[excel_file_topic, num_topics_topic, sample_size_topic, 
                           api_type_topic, model_name_topic, temperature_topic],
                    outputs=[topic_output]
                )
            
            with gr.Accordion("ğŸ“Š è´¨é‡è¯„ä¼°", open=False):
                eval_btn = gr.Button("ğŸ“Š è´¨é‡è¯„ä¼°", variant="secondary")
                eval_output = gr.JSON(label="è¯„ä¼°ç»“æœ")
                eval_btn.click(run_evaluation_only, outputs=[eval_output])
        
        with gr.Tab("ğŸ“ˆ ç»“æœæŸ¥çœ‹"):
            gr.Markdown("### ç»“æœæ‘˜è¦")
            
            refresh_btn = gr.Button("ğŸ”„ åˆ·æ–°ç»“æœ", variant="secondary")
            summary_output = gr.Textbox(label="ç»“æœæ‘˜è¦", lines=10, interactive=False)
            
            refresh_btn.click(get_results_summary, outputs=[summary_output])
            
            gr.Markdown("### ç”Ÿæˆçš„æ–‡ä»¶")
            gr.Markdown("""
            - `data/input/dataset.jsonl`: é¢„å¤„ç†åçš„æ•°æ®
            - `data/output/topicgpt_results/topicgpt_results.json`: è¯é¢˜å»ºæ¨¡ç»“æœ
            - `results/geval_results.json`: è´¨é‡è¯„ä¼°ç»“æœ
            - `results/evaluation_report.md`: è¯„ä¼°æŠ¥å‘Š
            - `results/optimization_report.md`: ä¼˜åŒ–æŠ¥å‘Š
            - `results/best_results.json`: æœ€ä½³ç»“æœ
            """)
        
        with gr.Tab("âš™ï¸ é…ç½®è¯´æ˜"):
            gr.Markdown("""
            ## å‚æ•°è¯´æ˜
            
            ### åŸºæœ¬å‚æ•°
            - **è¯é¢˜æ•°é‡**: è¦ç”Ÿæˆçš„è¯é¢˜æ•°é‡ï¼Œå»ºè®®3-15ä¸ª
            - **æœ€å¤§ä¼˜åŒ–è½®æ•°**: é—­ç¯ä¼˜åŒ–çš„æœ€å¤§è¿­ä»£æ¬¡æ•°
            - **é‡‡æ ·å¤§å°**: ä»æ•°æ®é›†ä¸­é‡‡æ ·çš„æ–‡æ¡£æ•°é‡
            
            ### æ¨¡å‹å‚æ•°
            - **APIç±»å‹**: 
              - `openai`: ä½¿ç”¨OpenAI APIï¼ˆéœ€è¦OPENAI_API_KEYï¼‰
              - `huggingface`: ä½¿ç”¨HuggingFace APIï¼ˆéœ€è¦HUGGINGFACE_API_KEYï¼‰
              - `local`: ä½¿ç”¨æœ¬åœ°æ¨¡å‹
            - **æ¨¡å‹åç§°**: å…·ä½“çš„æ¨¡å‹åç§°
            - **æ¸©åº¦å‚æ•°**: æ§åˆ¶è¾“å‡ºçš„éšæœºæ€§ï¼Œ0.1-1.0
            - **ä¼˜åŒ–é˜ˆå€¼**: ä½äºæ­¤åˆ†æ•°çš„è¯é¢˜å°†è¢«ä¼˜åŒ–
            
            ### è¯„ä¼°ç»´åº¦
            - **è¿è´¯æ€§ (Coherence)**: è¯é¢˜å†…éƒ¨è¯­ä¹‰ä¸€è‡´æ€§
            - **ä¸€è‡´æ€§ (Consistency)**: è¯é¢˜é—´çš„åŒºåˆ†åº¦
            - **æµç•…æ€§ (Fluency)**: è¯é¢˜æè¿°çš„è‡ªç„¶ç¨‹åº¦
            - **ç›¸å…³æ€§ (Relevance)**: è¯é¢˜ä¸æ–‡æ¡£çš„åŒ¹é…åº¦
            - **å¤šæ ·æ€§ (Diversity)**: è¯é¢˜è¦†ç›–çš„å¹¿åº¦
            """)
    
    return demo

def main():
    """ä¸»å‡½æ•°"""
    # è®¾ç½®ç¯å¢ƒ
    setup_environment()
    
    # åˆ›å»ºç•Œé¢
    demo = create_interface()
    
    # å¯åŠ¨æœåŠ¡
    demo.launch(
        server_name="0.0.0.0",
        server_port=7860,
        share=True,
        debug=True
    )

if __name__ == "__main__":
    main() 