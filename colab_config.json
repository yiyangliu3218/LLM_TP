{
  "api_type": "huggingface",
  "model_name": "all-MiniLM-L6-v2",
  "num_topics": 8,
  "max_iterations": 3,
  "sample_size": 1000,
  "temperature": 0.7,
  "max_tokens": 1000,
  "optimization_threshold": 3.0,
  "evaluation_aspects": [
    "coherence",
    "consistency",
    "fluency",
    "relevance",
    "diversity"
  ],
  "huggingface_config": {
    "api_key": null,
    "models": {
      "embedding_model": "sentence-transformers/all-MiniLM-L6-v2",
      "generation_model": "microsoft/DialoGPT-medium",
      "classification_model": "distilbert-base-uncased"
    },
    "use_local": false,
    "max_length": 512,
    "batch_size": 32
  },
  "topic_modeling_config": {
    "embedding_method": "sentence_transformers",
    "clustering_method": "kmeans",
    "n_clusters": 8,
    "random_state": 42,
    "min_topic_size": 10
  },
  "colab_config": {
    "use_gpu": true,
    "device": "cpu",
    "memory_efficient": true,
    "download_models": true
  },
  "free_models": {
    "embedding_models": [
      "sentence-transformers/all-MiniLM-L6-v2",
      "sentence-transformers/all-mpnet-base-v2",
      "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"
    ],
    "generation_models": [
      "microsoft/DialoGPT-medium",
      "gpt2",
      "distilgpt2"
    ],
    "classification_models": [
      "distilbert-base-uncased",
      "bert-base-uncased",
      "roberta-base"
    ]
  }
}