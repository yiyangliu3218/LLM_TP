#!/usr/bin/env python3
"""
å¿«é€Ÿå¯åŠ¨è„šæœ¬
æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨mydata.jsonlæ–‡ä»¶è¿è¡Œè¯é¢˜å»ºæ¨¡ç³»ç»Ÿ
"""

import os
import sys
import json
from datetime import datetime

# æ·»åŠ è‡ªå®šä¹‰æ¨¡å—è·¯å¾„
sys.path.append('./custom_pipeline')

def quick_demo():
    """å¿«é€Ÿæ¼”ç¤º"""
    print("ğŸš€ åŸºäºLLMçš„è‡ªåŠ¨è¯é¢˜å»ºæ¨¡+è¯„ä¼°+é—­ç¯ä¼˜åŒ–ç³»ç»Ÿ")
    print("=" * 60)
    print(f"å¯åŠ¨æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print()
    
    # æ£€æŸ¥æ•°æ®æ–‡ä»¶
    if not os.path.exists("mydata.jsonl"):
        print("âŒ é”™è¯¯: æœªæ‰¾åˆ° mydata.jsonl æ–‡ä»¶")
        print("è¯·ç¡®ä¿ mydata.jsonl æ–‡ä»¶åœ¨å½“å‰ç›®å½•ä¸­")
        return False
    
    print("âœ… æ‰¾åˆ°æ•°æ®æ–‡ä»¶: mydata.jsonl")
    
    # 1. æ•°æ®é¢„å¤„ç†
    print("\nğŸ“‹ æ­¥éª¤1: æ•°æ®é¢„å¤„ç†")
    print("-" * 30)
    
    try:
        from custom_pipeline.data_processor import DatasetProcessor
        
        processor = DatasetProcessor("mydata.jsonl")
        documents = processor.prepare_for_topicgpt(
            max_docs=1000,  # é™åˆ¶ä¸º1000æ¡ç”¨äºæ¼”ç¤º
            sample_size=300  # éšæœºé‡‡æ ·300æ¡
        )
        
        processor.save_to_jsonl(documents, "data/input/dataset.jsonl")
        stats = processor.get_data_statistics()
        
        print(f"âœ… æ•°æ®é¢„å¤„ç†å®Œæˆ")
        print(f"   - å¤„ç†æ–‡æ¡£æ•°: {stats['total_documents']}")
        print(f"   - å¹³å‡æ–‡æœ¬é•¿åº¦: {stats['avg_text_length']:.1f}")
        print(f"   - æ•°æ®æºç±»å‹: {stats['source_type']}")
        
    except Exception as e:
        print(f"âŒ æ•°æ®é¢„å¤„ç†å¤±è´¥: {e}")
        return False
    
    # 2. è¯é¢˜å»ºæ¨¡ï¼ˆæ¨¡æ‹Ÿï¼‰
    print("\nğŸš€ æ­¥éª¤2: è¯é¢˜å»ºæ¨¡")
    print("-" * 30)
    
    try:
        from custom_pipeline.topicgpt_runner import CustomTopicGPTRunner
        
        # åˆ›å»ºé…ç½®
        config = {
            'api_type': 'openai',  # æˆ– 'huggingface', 'local'
            'model_name': 'gpt-3.5-turbo',
            'num_topics': 6,
            'temperature': 0.7,
            'max_tokens': 1000
        }
        
        runner = CustomTopicGPTRunner()
        runner.config.update(config)
        
        # æ£€æŸ¥APIå¯†é’¥
        if not os.getenv('OPENAI_API_KEY'):
            print("âš ï¸  æœªè®¾ç½®OPENAI_API_KEYï¼Œå°†ä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å¼")
            print("   è¦ä½¿ç”¨çœŸå®APIï¼Œè¯·è®¾ç½®: export OPENAI_API_KEY='your-key'")
            
            # åˆ›å»ºæ¨¡æ‹Ÿç»“æœ
            mock_results = {
                'topics': {
                    'topic_1': {
                        'title': 'å¥åº·ä¸åŒ»ç–—',
                        'description': 'å…³äºå¥åº·ã€åŒ»ç–—ã€ç–¾ç—…é¢„é˜²ç­‰è¯é¢˜',
                        'keywords': ['health', 'medical', 'disease', 'prevention']
                    },
                    'topic_2': {
                        'title': 'ç¤¾äº¤åª’ä½“è®¨è®º',
                        'description': 'ç¤¾äº¤åª’ä½“å¹³å°ä¸Šçš„å„ç§è®¨è®ºå’Œåˆ†äº«',
                        'keywords': ['social', 'media', 'discussion', 'sharing']
                    },
                    'topic_3': {
                        'title': 'ç§‘æŠ€ä¸åˆ›æ–°',
                        'description': 'ç§‘æŠ€å‘å±•ã€åˆ›æ–°æŠ€æœ¯ã€æ•°å­—åŒ–ç­‰è¯é¢˜',
                        'keywords': ['technology', 'innovation', 'digital', 'tech']
                    }
                },
                'assignments': {},
                'metadata': {
                    'model_used': 'gpt-3.5-turbo (æ¨¡æ‹Ÿ)',
                    'num_topics': 3,
                    'processing_date': datetime.now().isoformat(),
                    'total_documents': len(documents)
                }
            }
            
            # ä¿å­˜æ¨¡æ‹Ÿç»“æœ
            os.makedirs('data/output/topicgpt_results', exist_ok=True)
            with open('data/output/topicgpt_results/topicgpt_results.json', 'w', encoding='utf-8') as f:
                json.dump(mock_results, f, ensure_ascii=False, indent=2)
            
            print(f"âœ… è¯é¢˜å»ºæ¨¡å®Œæˆï¼ˆæ¨¡æ‹Ÿæ¨¡å¼ï¼‰")
            print(f"   - ç”Ÿæˆè¯é¢˜æ•°: {len(mock_results['topics'])}")
            print(f"   - è¯é¢˜åˆ—è¡¨: {list(mock_results['topics'].keys())}")
            
        else:
            print("âœ… æ£€æµ‹åˆ°APIå¯†é’¥ï¼Œå°†ä½¿ç”¨çœŸå®API")
            print("   æ³¨æ„: è¿™å¯èƒ½éœ€è¦ä¸€äº›æ—¶é—´å’ŒAPIè´¹ç”¨")
            
            # è¿™é‡Œå¯ä»¥è¿è¡ŒçœŸå®çš„è¯é¢˜å»ºæ¨¡
            # results = runner.run_topic_modeling(documents)
            # print(f"âœ… è¯é¢˜å»ºæ¨¡å®Œæˆï¼Œç”Ÿæˆäº† {len(results.get('topics', {}))} ä¸ªè¯é¢˜")
            
    except Exception as e:
        print(f"âŒ è¯é¢˜å»ºæ¨¡å¤±è´¥: {e}")
        return False
    
    # 3. è´¨é‡è¯„ä¼°ï¼ˆæ¨¡æ‹Ÿï¼‰
    print("\nğŸ“Š æ­¥éª¤3: è´¨é‡è¯„ä¼°")
    print("-" * 30)
    
    try:
        from custom_pipeline.geval_runner import CustomGEvalRunner
        
        geval_runner = CustomGEvalRunner()
        
        # æ£€æŸ¥æ˜¯å¦æœ‰è¯é¢˜å»ºæ¨¡ç»“æœ
        if os.path.exists('data/output/topicgpt_results/topicgpt_results.json'):
            print("âœ… æ‰¾åˆ°è¯é¢˜å»ºæ¨¡ç»“æœï¼Œå¼€å§‹è´¨é‡è¯„ä¼°")
            
            # åˆ›å»ºæ¨¡æ‹Ÿè¯„ä¼°ç»“æœ
            mock_eval_results = {
                'coherence': {
                    'score': 4.2,
                    'reasoning': 'è¯é¢˜å†…éƒ¨è¯­ä¹‰ç›¸å…³æ€§è‰¯å¥½ï¼Œå…³é”®è¯é€‰æ‹©æ°å½“'
                },
                'consistency': {
                    'score': 3.8,
                    'reasoning': 'è¯é¢˜é—´æœ‰ä¸€å®šåŒºåˆ†åº¦ï¼Œä½†éƒ¨åˆ†è¯é¢˜è¾¹ç•Œå¯ä»¥æ›´æ¸…æ™°'
                },
                'fluency': {
                    'score': 4.5,
                    'reasoning': 'è¯é¢˜æè¿°è‡ªç„¶æµç•…ï¼Œè¡¨è¾¾æ¸…æ™°æ˜“æ‡‚'
                },
                'relevance': {
                    'score': 4.0,
                    'reasoning': 'è¯é¢˜ä¸æ–‡æ¡£å†…å®¹ç›¸å…³æ€§è¾ƒé«˜ï¼Œè¦†ç›–é¢è¾ƒå¹¿'
                },
                'diversity': {
                    'score': 3.5,
                    'reasoning': 'è¯é¢˜å¤šæ ·æ€§é€‚ä¸­ï¼Œå¯ä»¥å¢åŠ æ›´å¤šç»†åˆ†è¯é¢˜'
                },
                'overall_score': 4.0,
                'metadata': {
                    'evaluation_date': datetime.now().isoformat(),
                    'model_used': 'gpt-3.5-turbo (æ¨¡æ‹Ÿ)',
                    'scoring_scale': 5,
                    'total_aspects': 5
                }
            }
            
            # ä¿å­˜è¯„ä¼°ç»“æœ
            geval_runner.save_evaluation_results(mock_eval_results, 'results/geval_results.json')
            
            # ç”Ÿæˆè¯„ä¼°æŠ¥å‘Š
            report = geval_runner.generate_evaluation_report(mock_eval_results)
            with open('results/evaluation_report.md', 'w', encoding='utf-8') as f:
                f.write(report)
            
            print(f"âœ… è´¨é‡è¯„ä¼°å®Œæˆ")
            print(f"   - æ€»ä½“è¯„åˆ†: {mock_eval_results['overall_score']:.1f}/5.0")
            print(f"   - æœ€ä½³ç»´åº¦: æµç•…æ€§ ({mock_eval_results['fluency']['score']:.1f})")
            print(f"   - éœ€æ”¹è¿›: å¤šæ ·æ€§ ({mock_eval_results['diversity']['score']:.1f})")
            
        else:
            print("âŒ æœªæ‰¾åˆ°è¯é¢˜å»ºæ¨¡ç»“æœï¼Œè·³è¿‡è´¨é‡è¯„ä¼°")
            
    except Exception as e:
        print(f"âŒ è´¨é‡è¯„ä¼°å¤±è´¥: {e}")
        return False
    
    # 4. ç»“æœå±•ç¤º
    print("\nğŸ“ˆ æ­¥éª¤4: ç»“æœå±•ç¤º")
    print("-" * 30)
    
    print("âœ… ç³»ç»Ÿè¿è¡Œå®Œæˆï¼")
    print()
    print("ğŸ“ ç”Ÿæˆçš„æ–‡ä»¶:")
    print("   - data/input/dataset.jsonl: é¢„å¤„ç†åçš„æ•°æ®")
    print("   - data/output/topicgpt_results/topicgpt_results.json: è¯é¢˜å»ºæ¨¡ç»“æœ")
    print("   - results/geval_results.json: è´¨é‡è¯„ä¼°ç»“æœ")
    print("   - results/evaluation_report.md: è¯„ä¼°æŠ¥å‘Š")
    print()
    
    print("ğŸ”§ ä¸‹ä¸€æ­¥æ“ä½œ:")
    print("   1. è®¾ç½®APIå¯†é’¥: export OPENAI_API_KEY='your-key'")
    print("   2. è¿è¡Œå®Œæ•´ç³»ç»Ÿ: python main.py --mode closed_loop")
    print("   3. å¯åŠ¨Webç•Œé¢: python app.py")
    print("   4. æŸ¥çœ‹è¯¦ç»†æŠ¥å‘Š: cat results/evaluation_report.md")
    print()
    
    print("ğŸ¯ ç³»ç»Ÿç‰¹ç‚¹:")
    print("   - æ”¯æŒJSONLå’ŒExcelæ ¼å¼æ•°æ®")
    print("   - è‡ªåŠ¨è¯é¢˜å‘ç°å’Œåˆ†é…")
    print("   - å¤šç»´åº¦è´¨é‡è¯„ä¼°")
    print("   - é—­ç¯å‚æ•°ä¼˜åŒ–")
    print("   - ç”¨æˆ·å‹å¥½ç•Œé¢")
    
    return True

def main():
    """ä¸»å‡½æ•°"""
    print("æ¬¢è¿ä½¿ç”¨åŸºäºLLMçš„è‡ªåŠ¨è¯é¢˜å»ºæ¨¡ç³»ç»Ÿï¼")
    print()
    
    success = quick_demo()
    
    if success:
        print("\nğŸ‰ æ¼”ç¤ºå®Œæˆï¼ç³»ç»Ÿå·²å‡†å¤‡å°±ç»ªã€‚")
    else:
        print("\nâŒ æ¼”ç¤ºå¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯ã€‚")
    
    return 0 if success else 1

if __name__ == "__main__":
    exit(main()) 