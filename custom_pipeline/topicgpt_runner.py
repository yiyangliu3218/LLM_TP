import sys
import os
import json
import yaml
from typing import Dict, List, Any
from datetime import datetime

# æ·»åŠ TopicGPTè·¯å¾„
sys.path.append('./topicGPT')

class CustomTopicGPTRunner:
    def __init__(self, config_path: str = None):
        """åˆå§‹åŒ–TopicGPTè¿è¡Œå™¨"""
        self.config = self.load_config(config_path)
        self.results = {}
        
    def load_config(self, config_path: str = None) -> Dict[str, Any]:
        """åŠ è½½é…ç½®"""
        if config_path and os.path.exists(config_path):
            with open(config_path, 'r', encoding='utf-8') as f:
                config = yaml.safe_load(f)
        else:
            # é»˜è®¤é…ç½®
            config = {
                'data_path': 'data/input/dataset.jsonl',
                'output_path': 'data/output/topicgpt_results',
                'model_name': 'gpt-3.5-turbo',  # å¯ä»¥æ”¹ä¸ºå¼€æºæ¨¡å‹
                'num_topics': 8,
                'language': 'english',
                'max_iterations': 3,
                'temperature': 0.7,
                'max_tokens': 1000,
                'api_type': 'openai',  # æˆ– 'huggingface', 'local'
                'model_config': {
                    'openai': {
                        'api_key': os.getenv('OPENAI_API_KEY', ''),
                        'base_url': os.getenv('OPENAI_BASE_URL', 'https://api.openai.com/v1')
                    },
                    'huggingface': {
                        'model_name': 'microsoft/DialoGPT-medium',
                        'api_key': os.getenv('HUGGINGFACE_API_KEY', '')
                    },
                    'local': {
                        'model_path': './models/llama-2-7b-chat',
                        'device': 'cuda' if os.getenv('CUDA_VISIBLE_DEVICES') else 'cpu'
                    }
                }
            }
        
        return config
    
    def setup_model(self):
        """è®¾ç½®æ¨¡å‹"""
        api_type = self.config['api_type']
        
        if api_type == 'openai':
            # ä½¿ç”¨OpenAI API
            import openai
            openai.api_key = self.config['model_config']['openai']['api_key']
            openai.base_url = self.config['model_config']['openai']['base_url']
            return 'openai'
            
        elif api_type == 'huggingface':
            # ä½¿ç”¨HuggingFace API
            return 'huggingface'
            
        elif api_type == 'local':
            # ä½¿ç”¨æœ¬åœ°æ¨¡å‹
            return 'local'
            
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„APIç±»å‹: {api_type}")
    
    def generate_topics_stage1(self, documents: List[Dict[str, Any]]) -> Dict[str, Any]:
        """ç¬¬ä¸€é˜¶æ®µï¼šç”Ÿæˆé«˜çº§è¯é¢˜"""
        print("ğŸš€ å¼€å§‹ç¬¬ä¸€é˜¶æ®µï¼šç”Ÿæˆé«˜çº§è¯é¢˜...")
        
        # æ„å»ºprompt
        prompt = self.build_stage1_prompt(documents)
        
        # è°ƒç”¨æ¨¡å‹
        response = self.call_model(prompt)
        
        # è§£æç»“æœ
        topics = self.parse_stage1_response(response)
        
        print(f"âœ… ç¬¬ä¸€é˜¶æ®µå®Œæˆï¼Œç”Ÿæˆäº† {len(topics)} ä¸ªé«˜çº§è¯é¢˜")
        return topics
    
    def generate_topics_stage2(self, stage1_topics: Dict[str, Any], 
                             documents: List[Dict[str, Any]]) -> Dict[str, Any]:
        """ç¬¬äºŒé˜¶æ®µï¼šç”Ÿæˆä½çº§è¯é¢˜"""
        print("ğŸš€ å¼€å§‹ç¬¬äºŒé˜¶æ®µï¼šç”Ÿæˆä½çº§è¯é¢˜...")
        
        detailed_topics = {}
        
        for topic_id, topic_info in stage1_topics.items():
            # ä¸ºæ¯ä¸ªé«˜çº§è¯é¢˜ç”Ÿæˆä½çº§è¯é¢˜
            prompt = self.build_stage2_prompt(topic_info, documents)
            response = self.call_model(prompt)
            
            subtopics = self.parse_stage2_response(response)
            detailed_topics[topic_id] = {
                'main_topic': topic_info,
                'subtopics': subtopics
            }
        
        print(f"âœ… ç¬¬äºŒé˜¶æ®µå®Œæˆï¼Œä¸º {len(stage1_topics)} ä¸ªé«˜çº§è¯é¢˜ç”Ÿæˆäº†å­è¯é¢˜")
        return detailed_topics
    
    def assign_topics(self, topics: Dict[str, Any], 
                     documents: List[Dict[str, Any]]) -> Dict[str, Any]:
        """åˆ†é…è¯é¢˜åˆ°æ–‡æ¡£"""
        print("ğŸš€ å¼€å§‹è¯é¢˜åˆ†é…...")
        
        assignments = {}
        
        for doc in documents:
            prompt = self.build_assignment_prompt(doc, topics)
            response = self.call_model(prompt)
            
            assignment = self.parse_assignment_response(response)
            assignments[doc['id']] = assignment
        
        print(f"âœ… è¯é¢˜åˆ†é…å®Œæˆï¼Œå¤„ç†äº† {len(documents)} ä¸ªæ–‡æ¡£")
        return assignments
    
    def refine_topics(self, topics: Dict[str, Any], 
                     assignments: Dict[str, Any]) -> Dict[str, Any]:
        """ç²¾ç‚¼è¯é¢˜"""
        print("ğŸš€ å¼€å§‹è¯é¢˜ç²¾ç‚¼...")
        
        # åˆ†æè¯é¢˜åˆ†å¸ƒ
        topic_distribution = self.analyze_topic_distribution(assignments)
        
        # è¯†åˆ«éœ€è¦åˆå¹¶æˆ–åˆ é™¤çš„è¯é¢˜
        refinement_prompt = self.build_refinement_prompt(topics, topic_distribution)
        response = self.call_model(refinement_prompt)
        
        refined_topics = self.parse_refinement_response(response, topics)
        
        print("âœ… è¯é¢˜ç²¾ç‚¼å®Œæˆ")
        return refined_topics
    
    def call_model(self, prompt: str) -> str:
        """è°ƒç”¨æ¨¡å‹"""
        api_type = self.config['api_type']
        
        if api_type == 'openai':
            return self.call_openai_model(prompt)
        elif api_type == 'huggingface':
            return self.call_huggingface_model(prompt)
        elif api_type == 'local':
            return self.call_local_model(prompt)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„APIç±»å‹: {api_type}")
    
    def call_openai_model(self, prompt: str) -> str:
        """è°ƒç”¨OpenAIæ¨¡å‹"""
        try:
            import openai
            response = openai.ChatCompletion.create(
                model=self.config['model_name'],
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„è¯é¢˜å»ºæ¨¡ä¸“å®¶ã€‚"},
                    {"role": "user", "content": prompt}
                ],
                temperature=self.config['temperature'],
                max_tokens=self.config['max_tokens']
            )
            return response.choices[0].message.content
        except Exception as e:
            print(f"OpenAI APIè°ƒç”¨å¤±è´¥: {e}")
            return self.get_fallback_response()
    
    def call_huggingface_model(self, prompt: str) -> str:
        """è°ƒç”¨HuggingFaceæ¨¡å‹"""
        try:
            import requests
            headers = {
                "Authorization": f"Bearer {self.config['model_config']['huggingface']['api_key']}",
                "Content-Type": "application/json"
            }
            
            payload = {
                "inputs": prompt,
                "parameters": {
                    "max_new_tokens": self.config['max_tokens'],
                    "temperature": self.config['temperature']
                }
            }
            
            response = requests.post(
                f"https://api-inference.huggingface.co/models/{self.config['model_config']['huggingface']['model_name']}",
                headers=headers,
                json=payload
            )
            
            if response.status_code == 200:
                return response.json()[0]['generated_text']
            else:
                print(f"HuggingFace APIè°ƒç”¨å¤±è´¥: {response.status_code}")
                return self.get_fallback_response()
                
        except Exception as e:
            print(f"HuggingFace APIè°ƒç”¨å¤±è´¥: {e}")
            return self.get_fallback_response()
    
    def call_local_model(self, prompt: str) -> str:
        """è°ƒç”¨æœ¬åœ°æ¨¡å‹"""
        try:
            # è¿™é‡Œå¯ä»¥é›†æˆæœ¬åœ°æ¨¡å‹ï¼Œå¦‚Llamaã€GPT4Allç­‰
            # ä¸ºäº†ç®€åŒ–ï¼Œè¿™é‡Œè¿”å›ä¸€ä¸ªç¤ºä¾‹å“åº”
            return self.get_fallback_response()
        except Exception as e:
            print(f"æœ¬åœ°æ¨¡å‹è°ƒç”¨å¤±è´¥: {e}")
            return self.get_fallback_response()
    
    def get_fallback_response(self) -> str:
        """è·å–å¤‡ç”¨å“åº”"""
        return "ç”±äºæ¨¡å‹è°ƒç”¨å¤±è´¥ï¼Œè¿”å›é»˜è®¤è¯é¢˜ã€‚"
    
    def build_stage1_prompt(self, documents: List[Dict[str, Any]]) -> str:
        """æ„å»ºç¬¬ä¸€é˜¶æ®µprompt"""
        sample_docs = documents[:10]  # å–å‰10ä¸ªæ–‡æ¡£ä½œä¸ºæ ·æœ¬
        
        prompt = f"""
        è¯·åˆ†æä»¥ä¸‹ç¤¾äº¤åª’ä½“å¸–å­ï¼Œç”Ÿæˆ {self.config['num_topics']} ä¸ªé«˜çº§è¯é¢˜ã€‚
        
        æ–‡æ¡£æ ·æœ¬ï¼š
        {json.dumps(sample_docs, ensure_ascii=False, indent=2)}
        
        è¦æ±‚ï¼š
        1. è¯é¢˜åº”è¯¥æ¶µç›–æ–‡æ¡£ä¸­çš„ä¸»è¦ä¸»é¢˜
        2. è¯é¢˜ä¹‹é—´åº”è¯¥æœ‰æ˜ç¡®çš„åŒºåˆ†
        3. æ¯ä¸ªè¯é¢˜åº”è¯¥æœ‰ä¸€ä¸ªæ¸…æ™°çš„æ ‡é¢˜å’Œæè¿°
        4. è¯é¢˜åº”è¯¥ä¸ç¤¾äº¤åª’ä½“å†…å®¹ç›¸å…³
        
        è¯·ä»¥JSONæ ¼å¼è¿”å›ç»“æœï¼š
        {{
            "topics": [
                {{
                    "id": "topic_1",
                    "title": "è¯é¢˜æ ‡é¢˜",
                    "description": "è¯é¢˜æè¿°",
                    "keywords": ["å…³é”®è¯1", "å…³é”®è¯2"]
                }}
            ]
        }}
        """
        return prompt
    
    def build_stage2_prompt(self, topic_info: Dict[str, Any], 
                           documents: List[Dict[str, Any]]) -> str:
        """æ„å»ºç¬¬äºŒé˜¶æ®µprompt"""
        prompt = f"""
        åŸºäºé«˜çº§è¯é¢˜ "{topic_info['title']}"ï¼Œè¯·ç”Ÿæˆ3-5ä¸ªå…·ä½“çš„å­è¯é¢˜ã€‚
        
        é«˜çº§è¯é¢˜æè¿°ï¼š{topic_info['description']}
        å…³é”®è¯ï¼š{topic_info['keywords']}
        
        è¯·ä¸ºè¿™ä¸ªé«˜çº§è¯é¢˜ç”Ÿæˆå…·ä½“çš„å­è¯é¢˜ï¼Œæ¯ä¸ªå­è¯é¢˜åº”è¯¥ï¼š
        1. æ›´åŠ å…·ä½“å’Œè¯¦ç»†
        2. åŒ…å«ç›¸å…³çš„å…³é”®è¯
        3. æœ‰æ˜ç¡®çš„è¾¹ç•Œ
        
        è¯·ä»¥JSONæ ¼å¼è¿”å›ç»“æœï¼š
        {{
            "subtopics": [
                {{
                    "id": "subtopic_1",
                    "title": "å­è¯é¢˜æ ‡é¢˜",
                    "description": "å­è¯é¢˜æè¿°",
                    "keywords": ["å…³é”®è¯1", "å…³é”®è¯2"]
                }}
            ]
        }}
        """
        return prompt
    
    def build_assignment_prompt(self, document: Dict[str, Any], 
                              topics: Dict[str, Any]) -> str:
        """æ„å»ºè¯é¢˜åˆ†é…prompt"""
        prompt = f"""
        è¯·å°†ä»¥ä¸‹æ–‡æ¡£åˆ†é…åˆ°æœ€åˆé€‚çš„è¯é¢˜ï¼š
        
        æ–‡æ¡£å†…å®¹ï¼š{document['text']}
        
        å¯ç”¨è¯é¢˜ï¼š
        {json.dumps(topics, ensure_ascii=False, indent=2)}
        
        è¯·è¿”å›ï¼š
        1. æœ€åˆé€‚çš„è¯é¢˜ID
        2. åˆ†é…ç†ç”±
        3. ç½®ä¿¡åº¦åˆ†æ•°ï¼ˆ0-1ï¼‰
        
        æ ¼å¼ï¼š
        {{
            "topic_id": "topic_1",
            "reasoning": "åˆ†é…ç†ç”±",
            "confidence": 0.85
        }}
        """
        return prompt
    
    def build_refinement_prompt(self, topics: Dict[str, Any], 
                               distribution: Dict[str, int]) -> str:
        """æ„å»ºç²¾ç‚¼prompt"""
        prompt = f"""
        åŸºäºè¯é¢˜åˆ†å¸ƒæƒ…å†µï¼Œè¯·ç²¾ç‚¼è¯é¢˜ï¼š
        
        è¯é¢˜åˆ†å¸ƒï¼š{distribution}
        
        è¯·ï¼š
        1. åˆå¹¶ç›¸ä¼¼çš„è¯é¢˜
        2. åˆ é™¤åˆ†é…æ–‡æ¡£å¤ªå°‘çš„è¯é¢˜
        3. ä¼˜åŒ–è¯é¢˜æè¿°
        
        è¿”å›ç²¾ç‚¼åçš„è¯é¢˜åˆ—è¡¨ã€‚
        """
        return prompt
    
    def parse_stage1_response(self, response: str) -> Dict[str, Any]:
        """è§£æç¬¬ä¸€é˜¶æ®µå“åº”"""
        try:
            # å°è¯•è§£æJSON
            if '{' in response and '}' in response:
                start = response.find('{')
                end = response.rfind('}') + 1
                json_str = response[start:end]
                data = json.loads(json_str)
                return {f"topic_{i+1}": topic for i, topic in enumerate(data.get('topics', []))}
        except:
            pass
        
        # å¦‚æœè§£æå¤±è´¥ï¼Œè¿”å›é»˜è®¤è¯é¢˜
        return {
            "topic_1": {"title": "ç¤¾äº¤åª’ä½“è®¨è®º", "description": "å…³äºç¤¾äº¤åª’ä½“çš„å„ç§è®¨è®º", "keywords": ["social", "media"]},
            "topic_2": {"title": "å¥åº·è¯é¢˜", "description": "å¥åº·ç›¸å…³çš„è®¨è®º", "keywords": ["health", "medical"]}
        }
    
    def parse_stage2_response(self, response: str) -> List[Dict[str, Any]]:
        """è§£æç¬¬äºŒé˜¶æ®µå“åº”"""
        try:
            if '{' in response and '}' in response:
                start = response.find('{')
                end = response.rfind('}') + 1
                json_str = response[start:end]
                data = json.loads(json_str)
                return data.get('subtopics', [])
        except:
            pass
        
        return []
    
    def parse_assignment_response(self, response: str) -> Dict[str, Any]:
        """è§£æè¯é¢˜åˆ†é…å“åº”"""
        try:
            if '{' in response and '}' in response:
                start = response.find('{')
                end = response.rfind('}') + 1
                json_str = response[start:end]
                return json.loads(json_str)
        except:
            pass
        
        return {"topic_id": "topic_1", "reasoning": "é»˜è®¤åˆ†é…", "confidence": 0.5}
    
    def parse_refinement_response(self, response: str, original_topics: Dict[str, Any]) -> Dict[str, Any]:
        """è§£æç²¾ç‚¼å“åº”"""
        # ç®€åŒ–å¤„ç†ï¼Œè¿”å›åŸå§‹è¯é¢˜
        return original_topics
    
    def analyze_topic_distribution(self, assignments: Dict[str, Any]) -> Dict[str, int]:
        """åˆ†æè¯é¢˜åˆ†å¸ƒ"""
        distribution = {}
        for doc_id, assignment in assignments.items():
            topic_id = assignment.get('topic_id', 'unknown')
            distribution[topic_id] = distribution.get(topic_id, 0) + 1
        return distribution
    
    def run_topic_modeling(self, documents: List[Dict[str, Any]]) -> Dict[str, Any]:
        """è¿è¡Œå®Œæ•´çš„è¯é¢˜å»ºæ¨¡æµç¨‹"""
        print("ğŸ¯ å¼€å§‹TopicGPTè¯é¢˜å»ºæ¨¡æµç¨‹...")
        
        # è®¾ç½®æ¨¡å‹
        self.setup_model()
        
        # ç¬¬ä¸€é˜¶æ®µï¼šç”Ÿæˆé«˜çº§è¯é¢˜
        stage1_topics = self.generate_topics_stage1(documents)
        
        # ç¬¬äºŒé˜¶æ®µï¼šç”Ÿæˆä½çº§è¯é¢˜
        stage2_topics = self.generate_topics_stage2(stage1_topics, documents)
        
        # è¯é¢˜åˆ†é…
        assignments = self.assign_topics(stage2_topics, documents)
        
        # è¯é¢˜ç²¾ç‚¼
        refined_topics = self.refine_topics(stage2_topics, assignments)
        
        # ä¿å­˜ç»“æœ
        results = {
            'topics': refined_topics,
            'assignments': assignments,
            'metadata': {
                'model_used': self.config['model_name'],
                'num_topics': self.config['num_topics'],
                'processing_date': datetime.now().isoformat(),
                'total_documents': len(documents)
            }
        }
        
        self.save_results(results)
        return results
    
    def save_results(self, results: Dict[str, Any]):
        """ä¿å­˜ç»“æœ"""
        os.makedirs(self.config['output_path'], exist_ok=True)
        
        output_file = os.path.join(self.config['output_path'], 'topicgpt_results.json')
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
        
        print(f"ç»“æœå·²ä¿å­˜åˆ°: {output_file}")

def main():
    """æµ‹è¯•TopicGPTè¿è¡Œå™¨"""
    # åŠ è½½æµ‹è¯•æ•°æ®
    with open('data/input/dataset.jsonl', 'r', encoding='utf-8') as f:
        documents = [json.loads(line) for line in f]
    
    # åˆ›å»ºè¿è¡Œå™¨
    runner = CustomTopicGPTRunner()
    
    # è¿è¡Œè¯é¢˜å»ºæ¨¡
    results = runner.run_topic_modeling(documents[:100])  # ä½¿ç”¨å‰100ä¸ªæ–‡æ¡£æµ‹è¯•
    
    print("è¯é¢˜å»ºæ¨¡å®Œæˆï¼")

if __name__ == "__main__":
    main() 