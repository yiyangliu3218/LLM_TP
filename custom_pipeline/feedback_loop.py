import json
import os
from typing import Dict, List, Any, Tuple
from datetime import datetime

class FeedbackOptimizer:
    def __init__(self, config: Dict[str, Any] = None):
        """åˆå§‹åŒ–åé¦ˆä¼˜åŒ–å™¨"""
        self.config = config or self.get_default_config()
        self.optimization_history = []
        self.improvement_strategies = {
            "coherence": self.improve_coherence,
            "consistency": self.improve_consistency,
            "fluency": self.improve_fluency,
            "relevance": self.improve_relevance,
            "diversity": self.improve_diversity
        }
        
    def get_default_config(self) -> Dict[str, Any]:
        """è·å–é»˜è®¤é…ç½®"""
        return {
            'optimization_threshold': 3.0,  # ä½äºæ­¤åˆ†æ•°è®¤ä¸ºéœ€è¦ä¼˜åŒ–
            'max_iterations': 5,            # æœ€å¤§ä¼˜åŒ–è½®æ•°
            'improvement_threshold': 0.1,   # æ”¹è¿›é˜ˆå€¼
            'parameter_bounds': {
                'num_topics': (3, 15),
                'temperature': (0.1, 0.9),
                'max_tokens': (500, 2000)
            }
        }
    
    def analyze_evaluation_results(self, eval_results: Dict[str, Any]) -> List[Dict[str, Any]]:
        """åˆ†æè¯„ä¼°ç»“æœï¼Œè¯†åˆ«éœ€è¦æ”¹è¿›çš„æ–¹é¢"""
        weak_aspects = []
        threshold = self.config['optimization_threshold']
        
        for aspect, result in eval_results.items():
            if aspect not in ['overall_score', 'metadata']:
                score = result.get('score', 3.0)
                if score < threshold:
                    weak_aspects.append({
                        'aspect': aspect,
                        'score': score,
                        'reasoning': result.get('reasoning', ''),
                        'improvement_potential': threshold - score
                    })
        
        # æŒ‰æ”¹è¿›æ½œåŠ›æ’åº
        weak_aspects.sort(key=lambda x: x['improvement_potential'], reverse=True)
        
        return weak_aspects
    
    def generate_optimization_strategy(self, weak_aspects: List[Dict[str, Any]], 
                                     current_config: Dict[str, Any]) -> Dict[str, Any]:
        """åŸºäºå¼±ç‚¹ç”Ÿæˆä¼˜åŒ–ç­–ç•¥"""
        optimizations = {}
        
        for weak_aspect in weak_aspects:
            aspect_name = weak_aspect['aspect']
            if aspect_name in self.improvement_strategies:
                optimization = self.improvement_strategies[aspect_name](
                    weak_aspect, current_config
                )
                optimizations[aspect_name] = optimization
        
        return optimizations
    
    def improve_coherence(self, weak_aspect: Dict[str, Any], 
                         config: Dict[str, Any]) -> Dict[str, Any]:
        """æ”¹è¿›è¯é¢˜è¿è´¯æ€§çš„ç­–ç•¥"""
        return {
            "prompt_modification": """
            ç‰¹åˆ«æ³¨æ„ï¼šç¡®ä¿æ¯ä¸ªè¯é¢˜çš„å…³é”®è¯åœ¨è¯­ä¹‰ä¸Šé«˜åº¦ç›¸å…³ã€‚
            åœ¨ç”Ÿæˆè¯é¢˜æ—¶ï¼Œè¯·éªŒè¯å…³é”®è¯æ˜¯å¦éƒ½å›´ç»•åŒä¸€ä¸ªæ ¸å¿ƒæ¦‚å¿µã€‚
            å»ºè®®ä½¿ç”¨æ›´ä¸¥æ ¼çš„è¯­ä¹‰ä¸€è‡´æ€§æ£€æŸ¥ã€‚
            """,
            "parameter_adjustment": {
                "temperature": max(0.1, config.get('temperature', 0.7) - 0.2),  # é™ä½éšæœºæ€§
                "top_p": min(0.8, config.get('top_p', 0.9) - 0.1),
                "frequency_penalty": min(0.5, config.get('frequency_penalty', 0.0) + 0.1)
            },
            "additional_instructions": [
                "åœ¨ç”Ÿæˆè¯é¢˜æ—¶ï¼Œç¡®ä¿å…³é”®è¯ä¹‹é—´æœ‰æ˜ç¡®çš„è¯­ä¹‰å…³è”",
                "é¿å…åœ¨åŒä¸€ä¸ªè¯é¢˜ä¸­åŒ…å«è¯­ä¹‰ä¸ç›¸å…³çš„è¯æ±‡",
                "ä½¿ç”¨æ›´ç²¾ç¡®çš„è¯é¢˜æè¿°æ¥å¢å¼ºè¿è´¯æ€§"
            ]
        }
    
    def improve_consistency(self, weak_aspect: Dict[str, Any], 
                           config: Dict[str, Any]) -> Dict[str, Any]:
        """æ”¹è¿›è¯é¢˜ä¸€è‡´æ€§çš„ç­–ç•¥"""
        return {
            "prompt_modification": """
            åœ¨ç”Ÿæˆå¤šä¸ªè¯é¢˜æ—¶ï¼Œè¯·ç¡®ä¿ï¼š
            1. è¯é¢˜ä¹‹é—´æœ‰æ˜ç¡®çš„åŒºåˆ†ç•Œé™
            2. é¿å…è¯é¢˜å†…å®¹é‡å 
            3. ä½¿ç”¨ä¸€è‡´çš„å‘½åå’Œæè¿°æ ¼å¼
            4. å»ºç«‹æ¸…æ™°çš„è¯é¢˜å±‚æ¬¡ç»“æ„
            """,
            "parameter_adjustment": {
                "num_topics": max(3, config.get('num_topics', 8) - 1),  # å‡å°‘è¯é¢˜æ•°é‡æé«˜åŒºåˆ†åº¦
                "temperature": max(0.1, config.get('temperature', 0.7) - 0.1),
                "presence_penalty": min(0.5, config.get('presence_penalty', 0.0) + 0.1)
            },
            "additional_instructions": [
                "åœ¨ç”Ÿæˆè¯é¢˜å‰ï¼Œå…ˆå®šä¹‰æ˜ç¡®çš„è¯é¢˜è¾¹ç•Œ",
                "ä½¿ç”¨å¯¹æ¯”åˆ†æç¡®ä¿è¯é¢˜é—´çš„å·®å¼‚æ€§",
                "å»ºç«‹ç»Ÿä¸€çš„è¯é¢˜å‘½åè§„èŒƒ"
            ]
        }
    
    def improve_fluency(self, weak_aspect: Dict[str, Any], 
                       config: Dict[str, Any]) -> Dict[str, Any]:
        """æ”¹è¿›æµç•…æ€§çš„ç­–ç•¥"""
        return {
            "prompt_modification": """
            è¯·ç¡®ä¿è¯é¢˜æè¿°å’Œå…³é”®è¯è¡¨è¾¾è‡ªç„¶æµç•…ï¼š
            1. ä½¿ç”¨æ¸…æ™°ã€ç®€æ´çš„è¯­è¨€
            2. é¿å…å†—ä½™å’Œé‡å¤è¡¨è¾¾
            3. ä¿æŒè¯­è¨€é£æ ¼çš„ä¸€è‡´æ€§
            4. ä½¿ç”¨å‡†ç¡®çš„æœ¯è¯­å’Œè¡¨è¾¾
            """,
            "parameter_adjustment": {
                "temperature": min(0.9, config.get('temperature', 0.7) + 0.1),  # å¢åŠ åˆ›é€ æ€§
                "max_tokens": min(2000, config.get('max_tokens', 1000) + 200)
            },
            "additional_instructions": [
                "åœ¨ç”Ÿæˆè¯é¢˜æè¿°æ—¶ï¼Œä½¿ç”¨è‡ªç„¶æµç•…çš„è¡¨è¾¾",
                "é¿å…ä½¿ç”¨è¿‡äºæŠ€æœ¯åŒ–æˆ–æ™¦æ¶©çš„è¯æ±‡",
                "ç¡®ä¿è¯é¢˜æ ‡é¢˜ç®€æ´æ˜äº†"
            ]
        }
    
    def improve_relevance(self, weak_aspect: Dict[str, Any], 
                         config: Dict[str, Any]) -> Dict[str, Any]:
        """æ”¹è¿›ç›¸å…³æ€§çš„ç­–ç•¥"""
        return {
            "prompt_modification": """
            è¯·ç¡®ä¿è¯é¢˜ä¸åŸå§‹æ–‡æ¡£é«˜åº¦ç›¸å…³ï¼š
            1. ä»”ç»†åˆ†ææ–‡æ¡£å†…å®¹çš„ä¸»è¦ä¸»é¢˜
            2. ç¡®ä¿è¯é¢˜å‡†ç¡®åæ˜ æ–‡æ¡£çš„æ ¸å¿ƒå†…å®¹
            3. é¿å…ç”Ÿæˆä¸æ–‡æ¡£æ— å…³çš„è¯é¢˜
            4. è€ƒè™‘æ–‡æ¡£çš„ä¸Šä¸‹æ–‡å’ŒèƒŒæ™¯
            """,
            "parameter_adjustment": {
                "temperature": max(0.1, config.get('temperature', 0.7) - 0.15),
                "top_p": min(0.9, config.get('top_p', 0.9) - 0.05)
            },
            "additional_instructions": [
                "åœ¨ç”Ÿæˆè¯é¢˜å‰ï¼Œæ·±å…¥åˆ†ææ–‡æ¡£å†…å®¹",
                "ç¡®ä¿æ¯ä¸ªè¯é¢˜éƒ½æœ‰å……åˆ†çš„æ–‡æ¡£æ”¯æŒ",
                "é¿å…ç”Ÿæˆè¿‡äºå®½æ³›æˆ–è¿‡äºç‹­çª„çš„è¯é¢˜"
            ]
        }
    
    def improve_diversity(self, weak_aspect: Dict[str, Any], 
                         config: Dict[str, Any]) -> Dict[str, Any]:
        """æ”¹è¿›å¤šæ ·æ€§çš„ç­–ç•¥"""
        return {
            "prompt_modification": """
            è¯·ç¡®ä¿è¯é¢˜å…·æœ‰è¶³å¤Ÿçš„å¤šæ ·æ€§ï¼š
            1. æ¶µç›–ä¸åŒçš„ä¸»é¢˜é¢†åŸŸå’Œè§’åº¦
            2. é¿å…è¯é¢˜é‡å¤å’Œç›¸ä¼¼æ€§
            3. ç¡®ä¿è¯é¢˜åˆ†å¸ƒå‡è¡¡
            4. è€ƒè™‘ä¸åŒç»´åº¦çš„ä¸»é¢˜åˆ’åˆ†
            """,
            "parameter_adjustment": {
                "num_topics": min(15, config.get('num_topics', 8) + 1),  # å¢åŠ è¯é¢˜æ•°é‡
                "temperature": min(0.9, config.get('temperature', 0.7) + 0.2),  # å¢åŠ å¤šæ ·æ€§
                "frequency_penalty": max(0.0, config.get('frequency_penalty', 0.0) - 0.1)
            },
            "additional_instructions": [
                "åœ¨ç”Ÿæˆè¯é¢˜æ—¶ï¼Œè€ƒè™‘ä¸åŒçš„ä¸»é¢˜ç»´åº¦",
                "ç¡®ä¿è¯é¢˜æ¶µç›–æ–‡æ¡£ä¸­çš„å„ç§ä¸»é¢˜",
                "é¿å…ç”Ÿæˆè¿‡äºç›¸ä¼¼çš„è¯é¢˜"
            ]
        }
    
    def apply_optimizations(self, config: Dict[str, Any], 
                           optimizations: Dict[str, Any]) -> Dict[str, Any]:
        """åº”ç”¨ä¼˜åŒ–ç­–ç•¥åˆ°é…ç½®ä¸­"""
        new_config = config.copy()
        
        # åˆå¹¶æ‰€æœ‰ä¼˜åŒ–ç­–ç•¥
        combined_optimization = {
            "parameter_adjustment": {},
            "prompt_modification": "",
            "additional_instructions": []
        }
        
        for aspect, optimization in optimizations.items():
            # åˆå¹¶å‚æ•°è°ƒæ•´
            if 'parameter_adjustment' in optimization:
                for param, value in optimization['parameter_adjustment'].items():
                    if param in combined_optimization["parameter_adjustment"]:
                        # å¦‚æœå‚æ•°å·²å­˜åœ¨ï¼Œå–å¹³å‡å€¼æˆ–æœ€ä¿å®ˆçš„å€¼
                        current_val = combined_optimization["parameter_adjustment"][param]
                        if isinstance(value, (int, float)) and isinstance(current_val, (int, float)):
                            combined_optimization["parameter_adjustment"][param] = (current_val + value) / 2
                    else:
                        combined_optimization["parameter_adjustment"][param] = value
            
            # åˆå¹¶promptä¿®æ”¹
            if 'prompt_modification' in optimization:
                combined_optimization["prompt_modification"] += "\n" + optimization['prompt_modification']
            
            # åˆå¹¶é¢å¤–æŒ‡ä»¤
            if 'additional_instructions' in optimization:
                combined_optimization["additional_instructions"].extend(optimization['additional_instructions'])
        
        # åº”ç”¨å‚æ•°è°ƒæ•´
        new_config.update(combined_optimization["parameter_adjustment"])
        
        # åº”ç”¨promptä¿®æ”¹
        if combined_optimization["prompt_modification"]:
            new_config['additional_instructions'] = new_config.get('additional_instructions', '') + '\n' + combined_optimization["prompt_modification"]
        
        # åº”ç”¨é¢å¤–æŒ‡ä»¤
        if combined_optimization["additional_instructions"]:
            new_config['optimization_instructions'] = combined_optimization["additional_instructions"]
        
        return new_config
    
    def validate_optimization(self, old_score: float, new_score: float) -> bool:
        """éªŒè¯ä¼˜åŒ–æ˜¯å¦æœ‰æ•ˆ"""
        improvement = new_score - old_score
        return improvement >= self.config['improvement_threshold']
    
    def record_optimization(self, iteration: int, old_config: Dict[str, Any], 
                          new_config: Dict[str, Any], old_score: float, 
                          new_score: float, weak_aspects: List[Dict[str, Any]]):
        """è®°å½•ä¼˜åŒ–å†å²"""
        optimization_record = {
            'iteration': iteration,
            'timestamp': datetime.now().isoformat(),
            'old_score': old_score,
            'new_score': new_score,
            'improvement': new_score - old_score,
            'weak_aspects': weak_aspects,
            'config_changes': {
                'old': old_config,
                'new': new_config
            }
        }
        
        self.optimization_history.append(optimization_record)
    
    def generate_optimization_report(self) -> str:
        """ç”Ÿæˆä¼˜åŒ–æŠ¥å‘Š"""
        if not self.optimization_history:
            return "æš‚æ— ä¼˜åŒ–å†å²è®°å½•"
        
        report = []
        report.append("# è¯é¢˜å»ºæ¨¡ä¼˜åŒ–æŠ¥å‘Š")
        report.append(f"\nä¼˜åŒ–æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        report.append(f"æ€»ä¼˜åŒ–è½®æ•°: {len(self.optimization_history)}")
        
        # è®¡ç®—æ€»ä½“æ”¹è¿›
        initial_score = self.optimization_history[0]['old_score']
        final_score = self.optimization_history[-1]['new_score']
        total_improvement = final_score - initial_score
        
        report.append(f"\n## ä¼˜åŒ–æ•ˆæœ")
        report.append(f"- åˆå§‹åˆ†æ•°: {initial_score:.2f}")
        report.append(f"- æœ€ç»ˆåˆ†æ•°: {final_score:.2f}")
        report.append(f"- æ€»ä½“æ”¹è¿›: {total_improvement:.2f}")
        report.append(f"- æ”¹è¿›ç™¾åˆ†æ¯”: {(total_improvement/initial_score)*100:.1f}%")
        
        report.append(f"\n## è¯¦ç»†ä¼˜åŒ–å†å²")
        for i, record in enumerate(self.optimization_history):
            report.append(f"\n### ç¬¬ {record['iteration']} è½®ä¼˜åŒ–")
            report.append(f"- æ—¶é—´: {record['timestamp']}")
            report.append(f"- åˆ†æ•°å˜åŒ–: {record['old_score']:.2f} â†’ {record['new_score']:.2f}")
            report.append(f"- æ”¹è¿›: {record['improvement']:.2f}")
            
            if record['weak_aspects']:
                report.append(f"- è¯†åˆ«çš„é—®é¢˜:")
                for aspect in record['weak_aspects']:
                    report.append(f"  - {aspect['aspect']}: {aspect['score']:.2f}")
        
        report.append(f"\n## é…ç½®å˜åŒ–æ€»ç»“")
        if len(self.optimization_history) > 1:
            initial_config = self.optimization_history[0]['config_changes']['old']
            final_config = self.optimization_history[-1]['config_changes']['new']
            
            for key in set(initial_config.keys()) | set(final_config.keys()):
                old_val = initial_config.get(key, 'N/A')
                new_val = final_config.get(key, 'N/A')
                if old_val != new_val:
                    report.append(f"- {key}: {old_val} â†’ {new_val}")
        
        return "\n".join(report)
    
    def save_optimization_history(self, output_path: str):
        """ä¿å­˜ä¼˜åŒ–å†å²"""
        os.makedirs(os.path.dirname(output_path), exist_ok=True)
        
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(self.optimization_history, f, ensure_ascii=False, indent=2)
        
        print(f"ä¼˜åŒ–å†å²å·²ä¿å­˜åˆ°: {output_path}")

class ClosedLoopTopicModeling:
    def __init__(self, excel_path: str, config: Dict[str, Any] = None):
        """åˆå§‹åŒ–é—­ç¯è¯é¢˜å»ºæ¨¡ç³»ç»Ÿ"""
        self.excel_path = excel_path
        self.config = config or {}
        
        # å¯¼å…¥å…¶ä»–æ¨¡å—
        from .data_processor import DatasetProcessor
        from .topicgpt_runner import CustomTopicGPTRunner
        from .geval_runner import CustomGEvalRunner
        
        self.data_processor = DatasetProcessor(excel_path)
        self.topicgpt_runner = CustomTopicGPTRunner()
        self.geval_runner = CustomGEvalRunner()
        self.optimizer = FeedbackOptimizer()
        
        self.best_results = None
        self.best_score = 0
        
    def run_complete_pipeline(self, max_iterations: int = 5, 
                            sample_size: int = 500) -> Dict[str, Any]:
        """è¿è¡Œå®Œæ•´çš„é—­ç¯ä¼˜åŒ–æµç¨‹"""
        
        print("ğŸ¯ å¼€å§‹é—­ç¯è¯é¢˜å»ºæ¨¡ç³»ç»Ÿ...")
        
        # æ•°æ®é¢„å¤„ç†
        print("ğŸ“‹ é¢„å¤„ç†æ•°æ®...")
        documents = self.data_processor.prepare_for_topicgpt(
            text_column="Translated Post Description",
            max_docs=1000,
            sample_size=sample_size
        )
        
        # ä¿å­˜é¢„å¤„ç†æ•°æ®
        self.data_processor.save_to_jsonl(documents, "data/input/dataset.jsonl")
        
        current_config = self.topicgpt_runner.config.copy()
        
        for iteration in range(max_iterations):
            print(f"\nğŸ”„ ç¬¬ {iteration + 1} è½®è¿­ä»£")
            
            # 1. è¿è¡ŒTopicGPT
            print("ğŸš€ è¿è¡Œè¯é¢˜å»ºæ¨¡...")
            topic_results = self.topicgpt_runner.run_topic_modeling(documents)
            
            # 2. è¿è¡ŒG-Evalè¯„ä¼°
            print("ğŸ“Š è¿è¡Œè´¨é‡è¯„ä¼°...")
            geval_input = self.geval_runner.prepare_geval_input(
                'data/output/topicgpt_results/topicgpt_results.json',
                'data/input/dataset.jsonl'
            )
            eval_results = self.geval_runner.run_evaluation(geval_input)
            
            current_score = eval_results['overall_score']
            print(f"æœ¬è½®æ€»åˆ†: {current_score:.2f}")
            
            # 3. æ£€æŸ¥æ˜¯å¦éœ€è¦ä¼˜åŒ–
            if current_score > self.best_score:
                self.best_score = current_score
                self.best_results = {
                    'topics': topic_results,
                    'evaluation': eval_results,
                    'iteration': iteration + 1,
                    'config': current_config.copy()
                }
            
            # å¦‚æœåˆ†æ•°è¶³å¤Ÿé«˜ï¼Œæå‰ç»“æŸ
            if current_score >= 4.0:
                print("âœ… è¾¾åˆ°æ»¡æ„åˆ†æ•°ï¼Œæå‰ç»“æŸä¼˜åŒ–")
                break
            
            # 4. ç”Ÿæˆä¼˜åŒ–ç­–ç•¥
            weak_aspects = self.optimizer.analyze_evaluation_results(eval_results)
            if weak_aspects:
                optimizations = self.optimizer.generate_optimization_strategy(
                    weak_aspects, current_config
                )
                
                # 5. åº”ç”¨ä¼˜åŒ–ç­–ç•¥
                old_config = current_config.copy()
                current_config = self.optimizer.apply_optimizations(current_config, optimizations)
                self.topicgpt_runner.config = current_config
                
                # è®°å½•ä¼˜åŒ–å†å²
                self.optimizer.record_optimization(
                    iteration + 1, old_config, current_config,
                    current_score, current_score, weak_aspects
                )
                
                print(f"åº”ç”¨ä¼˜åŒ–ç­–ç•¥: {list(optimizations.keys())}")
            else:
                print("æœªå‘ç°æ˜æ˜¾å¼±ç‚¹ï¼Œç»“æŸä¼˜åŒ–")
                break
        
        # ä¿å­˜æœ€ç»ˆç»“æœ
        self.save_final_results()
        
        return self.best_results
    
    def save_final_results(self):
        """ä¿å­˜æœ€ç»ˆç»“æœ"""
        if self.best_results:
            # ä¿å­˜æœ€ä½³ç»“æœ
            with open('results/best_results.json', 'w', encoding='utf-8') as f:
                json.dump(self.best_results, f, ensure_ascii=False, indent=2)
            
            # ä¿å­˜ä¼˜åŒ–å†å²
            self.optimizer.save_optimization_history('results/optimization_history.json')
            
            # ç”Ÿæˆä¼˜åŒ–æŠ¥å‘Š
            report = self.optimizer.generate_optimization_report()
            with open('results/optimization_report.md', 'w', encoding='utf-8') as f:
                f.write(report)
            
            print(f"âœ… æœ€ç»ˆç»“æœå·²ä¿å­˜ï¼Œæœ€ä½³åˆ†æ•°: {self.best_score:.2f}")

def main():
    """æµ‹è¯•é—­ç¯ç³»ç»Ÿ"""
    # åˆ›å»ºé—­ç¯ç³»ç»Ÿ
    pipeline = ClosedLoopTopicModeling("Dataset.xlsx")
    
    # è¿è¡Œå®Œæ•´æµç¨‹
    results = pipeline.run_complete_pipeline(max_iterations=3, sample_size=300)
    
    print("é—­ç¯è¯é¢˜å»ºæ¨¡ç³»ç»Ÿè¿è¡Œå®Œæˆï¼")

if __name__ == "__main__":
    main() 